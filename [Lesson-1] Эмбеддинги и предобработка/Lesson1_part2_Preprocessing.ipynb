{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bee7fffc-8ad3-4a54-9483-3f908a372888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/iromaykin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/iromaykin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/iromaykin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/iromaykin/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt') \n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import pymorphy2\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2682fa2-81d2-4a2a-b494-5073113f9838",
   "metadata": {},
   "source": [
    "# Предобработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f242e4ed-a588-49c0-9577-b5d6f42fdc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self, method='lemmatization', tokenizer='word', language='russian'):\n",
    "        \"\"\"\n",
    "        Инициализация объекта класса предобработки текста.\n",
    "        \n",
    "        Параметры:\n",
    "            method (str): Метод обработки слов - 'stemming' или 'lemmatization'.\n",
    "            tokenizer (str): Тип токенизации - 'letter', 'word' или 'sentence'.\n",
    "            language (str): Язык текстов - 'russian' или 'english'\n",
    "        \"\"\"\n",
    "        self.method = method\n",
    "        self.tokenizer = tokenizer\n",
    "        self.language = language\n",
    "        self.stop_words = set(stopwords.words(self.language))\n",
    "        self.stemmer = SnowballStemmer(self.language)\n",
    "        self.lemmatizer_ru = pymorphy2.MorphAnalyzer()\n",
    "        self.lemmatizer_en = WordNetLemmatizer()\n",
    "    \n",
    "    def get_wordnet_pos(self, word):\n",
    "        \"\"\"Функция для преобразования POS-тегов из NLTK в формат, подходящий для WordNetLemmatizer\"\"\"\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "        tag_dict = {\n",
    "            'J': wordnet.ADJ,\n",
    "            'N': wordnet.NOUN,\n",
    "            'V': wordnet.VERB,\n",
    "            'R': wordnet.ADV\n",
    "        }\n",
    "        return tag_dict.get(tag, wordnet.NOUN)\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Удаляет спецсимволы, HTML-теги, ссылки и номера.\"\"\"\n",
    "        text = BeautifulSoup(text, \"html.parser\").get_text() # Удаляем HTML\n",
    "        text = re.sub(r'http\\S+', '', text)  # Удаление ссылок\n",
    "        text = re.sub(r'\\d+', '', text)  # Удаление номеров\n",
    "        if self.tokenizer == 'sentence':\n",
    "            text = re.sub('[^a-zA-Zа-яА-Я0-9.\\s]', '', text)  # Удаление пунктуации (кроме точки, т.к. она важна для разделения предложений\n",
    "            text = re.sub('\\.', ' . ', text)  # Разъединяем точку с словами\n",
    "        else:\n",
    "            text = re.sub('[^a-zA-Zа-яА-Я0-9\\s]', '', text)  # Удаление пунктуации\n",
    "        text = re.sub(r'\\s+', ' ', text) # удаление лишних пробелов\n",
    "        return text\n",
    "    \n",
    "    def to_lowercase(self, text):\n",
    "        \"\"\"Приводит текст к нижнему регистру.\"\"\"\n",
    "        return text.lower()\n",
    "    \n",
    "    def remove_stopwords(self, text):\n",
    "        \"\"\"Удаляет стоп-слова.\"\"\"\n",
    "        return ' '.join([word for word in text.split(' ') if word not in self.stop_words])\n",
    "    \n",
    "    def process_word(self, text):\n",
    "        \"\"\"Выполняет стемминг или лемматизацию слова в зависимости от выбранного метода.\"\"\"\n",
    "        text = text.split(' ')\n",
    "        if self.method == 'stemming':\n",
    "            result = [self.stemmer.stem(word) for word in text]\n",
    "        elif self.method == 'lemmatization' and self.language == 'russian':\n",
    "            result = [self.lemmatizer_ru.parse(word)[0].normal_form for word in text]\n",
    "        elif self.method == 'lemmatization' and self.language == 'english':\n",
    "            result = [self.lemmatizer_en.lemmatize(word, self.get_wordnet_pos(word)) for word in text]\n",
    "\n",
    "        return ' '.join(result)\n",
    "    \n",
    "    def tokenize(self, text):\n",
    "        \"\"\"Выполняет токенизацию текста.\"\"\"\n",
    "        if self.tokenizer == 'letter':\n",
    "            return list(text)\n",
    "        elif self.tokenizer == 'word':\n",
    "            return word_tokenize(text, language='russian')\n",
    "        elif self.tokenizer == 'sentence':\n",
    "            return sent_tokenize(text, language='russian')\n",
    "    \n",
    "    def preprocess_texts(self, texts):\n",
    "        \"\"\"Выполняет предобработку списка текстов.\"\"\"\n",
    "        processed_texts = []\n",
    "        for text in texts:\n",
    "            cleaned_text = self.clean_text(text)\n",
    "            lowercase_text = self.to_lowercase(cleaned_text)\n",
    "            text_without_stopwords = self.remove_stopwords(lowercase_text)\n",
    "            process_text = self.process_word(text_without_stopwords)\n",
    "            tokens = self.tokenize(process_text)\n",
    "            processed_texts.append(tokens)\n",
    "        \n",
    "        return processed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f585a039-dc39-4aea-a5cb-5f04e7c4f2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Default text: \n",
      "Пример текста для <b>предобработки</b>. Этот текст содержит ссылку http://example.com и номера 12345.         NLP — это область искусственного интеллекта, связанная с обработкой и анализом естественного языка.         Она включает в себя множество задач, таких как машинный перевод, анализ тональности, извлечение информации и многие другие.\n",
      "\n",
      " clean text: \n",
      "Пример текста для предобработки . Этот текст содержит ссылку и номера . NLP это область искусственного интеллекта связанная с обработкой и анализом естественного языка . Она включает в себя множество задач таких как машинный перевод анализ тональности извлечение информации и многие другие . \n",
      "\n",
      " lower_text: \n",
      "пример текста для предобработки . этот текст содержит ссылку и номера . nlp это область искусственного интеллекта связанная с обработкой и анализом естественного языка . она включает в себя множество задач таких как машинный перевод анализ тональности извлечение информации и многие другие . \n",
      "\n",
      " text_without_stopwords: \n",
      "пример текста предобработки . текст содержит ссылку номера . nlp это область искусственного интеллекта связанная обработкой анализом естественного языка . включает множество задач таких машинный перевод анализ тональности извлечение информации многие другие . \n",
      "\n",
      " lem_text: \n",
      "пример текст предобработка . текст содержать ссылка номер . nlp это область искусственный интеллект связать обработка анализ естественный язык . включать множество задача такой машинный перевод анализ тональность извлечение информация многие другой . \n",
      "\n",
      " tokens: \n",
      "['пример текст предобработка .', 'текст содержать ссылка номер .', 'nlp это область искусственный интеллект связать обработка анализ естественный язык .', 'включать множество задача такой машинный перевод анализ тональность извлечение информация многие другой .']\n"
     ]
    }
   ],
   "source": [
    "text = 'Пример текста для <b>предобработки</b>. Этот текст содержит ссылку http://example.com и номера 12345. \\\n",
    "        NLP — это область искусственного интеллекта, связанная с обработкой и анализом естественного языка. \\\n",
    "        Она включает в себя множество задач, таких как машинный перевод, анализ тональности, извлечение информации и многие другие.'\n",
    "\n",
    "preprocessor = TextPreprocessor(method='lemmatization', tokenizer='sentence', language='russian')\n",
    "print(' Default text: ')\n",
    "print(text)\n",
    "clean_text = preprocessor.clean_text(text)\n",
    "print('\\n clean text: ')\n",
    "print(clean_text)\n",
    "lower_text = preprocessor.to_lowercase(clean_text)\n",
    "print('\\n lower_text: ')\n",
    "print(lower_text)\n",
    "text_without_stopwords = preprocessor.remove_stopwords(lower_text)\n",
    "print('\\n text_without_stopwords: ')\n",
    "print(text_without_stopwords)\n",
    "lematize_text = preprocessor.process_word(text_without_stopwords)\n",
    "print('\\n lem_text: ')\n",
    "print(lematize_text)\n",
    "tokens = preprocessor.tokenize(lematize_text)\n",
    "print('\\n tokens: ')\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4fd1a58-0d7d-4c91-91a5-2ef5ed4de624",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming:\n",
      "['пример', 'текст', 'предобработк', 'текст', 'содерж', 'ссылк', 'номер', 'nlp', 'эт', 'област', 'искусствен', 'интеллект', 'связа', 'обработк', 'анализ', 'естествен', 'язык', 'включа', 'множеств', 'задач', 'так', 'машин', 'перевод', 'анализ', 'тональн', 'извлечен', 'информац', 'мног', 'друг']\n",
      "\n",
      "\n",
      "Lemmatization:\n",
      "['пример', 'текст', 'предобработка', 'текст', 'содержать', 'ссылка', 'номер', 'nlp', 'это', 'область', 'искусственный', 'интеллект', 'связать', 'обработка', 'анализ', 'естественный', 'язык', 'включать', 'множество', 'задача', 'такой', 'машинный', 'перевод', 'анализ', 'тональность', 'извлечение', 'информация', 'многие', 'другой']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Stemming:')\n",
    "preprocessor = TextPreprocessor(method='stemming', tokenizer='word', language='russian')\n",
    "processed_texts = preprocessor.preprocess_texts([text])\n",
    "for result in processed_texts:\n",
    "    print(result)\n",
    "    print('\\n')\n",
    "\n",
    "print('Lemmatization:')\n",
    "preprocessor = TextPreprocessor(method='lemmatization', tokenizer='word', language='russian')\n",
    "processed_texts = preprocessor.preprocess_texts([text])\n",
    "for result in processed_texts:\n",
    "    print(result)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041667ee-944f-460e-a69d-426883576605",
   "metadata": {},
   "source": [
    "# Тестирование влияния предобработки текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81ed8928-ef79-4275-a7f3-51393a2bcd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23921eea-b53a-4778-907f-46a2fdf53310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/interns_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"dair-ai/emotion\", \"split\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a322ffd7-6e09-4d50-a9d7-36d63b791f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>i feel very comfortable with this decision</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6103</th>\n",
       "      <td>i love that i feel valuable i love making the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7973</th>\n",
       "      <td>i could loose my job i would be so f amp ed fo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4730</th>\n",
       "      <td>i feel popular but they dont want to be taught...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>im feeling adventurous and my laundry hamper</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>im starting to feel wryly amused at the banal ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15676</th>\n",
       "      <td>i feel so much better about that number</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11708</th>\n",
       "      <td>i feel absolutely overwhelmed by it</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10285</th>\n",
       "      <td>i went to pick up the kids feeling scared and ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11697</th>\n",
       "      <td>i feel agitated</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "446           i feel very comfortable with this decision      1\n",
       "6103   i love that i feel valuable i love making the ...      1\n",
       "7973   i could loose my job i would be so f amp ed fo...      4\n",
       "4730   i feel popular but they dont want to be taught...      1\n",
       "1586        im feeling adventurous and my laundry hamper      1\n",
       "...                                                  ...    ...\n",
       "96     im starting to feel wryly amused at the banal ...      1\n",
       "15676            i feel so much better about that number      1\n",
       "11708                i feel absolutely overwhelmed by it      4\n",
       "10285  i went to pick up the kids feeling scared and ...      4\n",
       "11697                                    i feel agitated      3\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im updating my blog because i feel shitty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i never make her separate from me because i do...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was feeling a little vain when i did this one</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>i just keep feeling like someone is being unki...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>im feeling a little cranky negative after this...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>i feel that i am useful to my people and that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>im feeling more comfortable with derby i feel ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>i feel all weird when i have to meet w people ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     im feeling rather rotten so im not very ambiti...      0\n",
       "1             im updating my blog because i feel shitty      0\n",
       "2     i never make her separate from me because i do...      0\n",
       "3     i left with my bouquet of red and yellow tulip...      1\n",
       "4       i was feeling a little vain when i did this one      0\n",
       "...                                                 ...    ...\n",
       "1995  i just keep feeling like someone is being unki...      3\n",
       "1996  im feeling a little cranky negative after this...      3\n",
       "1997  i feel that i am useful to my people and that ...      1\n",
       "1998  im feeling more comfortable with derby i feel ...      1\n",
       "1999  i feel all weird when i have to meet w people ...      4\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = ds['train'].to_pandas().sample(4000)\n",
    "display(df_train)\n",
    "df_test = ds['test'].to_pandas()\n",
    "display(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfabe3f6-8445-4413-82ef-0dac357cb5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>i feel very comfortable with this decision</td>\n",
       "      <td>1</td>\n",
       "      <td>feel comfortable decision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6103</th>\n",
       "      <td>i love that i feel valuable i love making the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>love feel valuable love make choice love easy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7973</th>\n",
       "      <td>i could loose my job i would be so f amp ed fo...</td>\n",
       "      <td>4</td>\n",
       "      <td>could loose job would f amp ed xmas hate xmas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4730</th>\n",
       "      <td>i feel popular but they dont want to be taught...</td>\n",
       "      <td>1</td>\n",
       "      <td>feel popular dont want taught wont get married...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>im feeling adventurous and my laundry hamper</td>\n",
       "      <td>1</td>\n",
       "      <td>im feel adventurous laundry hamper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>im starting to feel wryly amused at the banal ...</td>\n",
       "      <td>1</td>\n",
       "      <td>im start feel wryly amuse banal comedy error l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15676</th>\n",
       "      <td>i feel so much better about that number</td>\n",
       "      <td>1</td>\n",
       "      <td>feel much well number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11708</th>\n",
       "      <td>i feel absolutely overwhelmed by it</td>\n",
       "      <td>4</td>\n",
       "      <td>feel absolutely overwhelmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10285</th>\n",
       "      <td>i went to pick up the kids feeling scared and ...</td>\n",
       "      <td>4</td>\n",
       "      <td>go pick kid feel scar trembly self critical st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11697</th>\n",
       "      <td>i feel agitated</td>\n",
       "      <td>3</td>\n",
       "      <td>feel agitate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "446           i feel very comfortable with this decision      1   \n",
       "6103   i love that i feel valuable i love making the ...      1   \n",
       "7973   i could loose my job i would be so f amp ed fo...      4   \n",
       "4730   i feel popular but they dont want to be taught...      1   \n",
       "1586        im feeling adventurous and my laundry hamper      1   \n",
       "...                                                  ...    ...   \n",
       "96     im starting to feel wryly amused at the banal ...      1   \n",
       "15676            i feel so much better about that number      1   \n",
       "11708                i feel absolutely overwhelmed by it      4   \n",
       "10285  i went to pick up the kids feeling scared and ...      4   \n",
       "11697                                    i feel agitated      3   \n",
       "\n",
       "                                       preprocessed_text  \n",
       "446                            feel comfortable decision  \n",
       "6103   love feel valuable love make choice love easy ...  \n",
       "7973   could loose job would f amp ed xmas hate xmas ...  \n",
       "4730   feel popular dont want taught wont get married...  \n",
       "1586                  im feel adventurous laundry hamper  \n",
       "...                                                  ...  \n",
       "96     im start feel wryly amuse banal comedy error l...  \n",
       "15676                              feel much well number  \n",
       "11708                        feel absolutely overwhelmed  \n",
       "10285  go pick kid feel scar trembly self critical st...  \n",
       "11697                                       feel agitate  \n",
       "\n",
       "[4000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
       "      <td>0</td>\n",
       "      <td>im feel rather rotten im ambitious right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im updating my blog because i feel shitty</td>\n",
       "      <td>0</td>\n",
       "      <td>im update blog feel shitty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i never make her separate from me because i do...</td>\n",
       "      <td>0</td>\n",
       "      <td>never make separate ever want feel like ashamed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
       "      <td>1</td>\n",
       "      <td>left bouquet red yellow tulip arm feel slightl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was feeling a little vain when i did this one</td>\n",
       "      <td>0</td>\n",
       "      <td>feel little vain one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>i just keep feeling like someone is being unki...</td>\n",
       "      <td>3</td>\n",
       "      <td>keep feel like someone unkind wrong think get ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>im feeling a little cranky negative after this...</td>\n",
       "      <td>3</td>\n",
       "      <td>im feel little cranky negative doctor appointment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>i feel that i am useful to my people and that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>feel useful people give great feel achievement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>im feeling more comfortable with derby i feel ...</td>\n",
       "      <td>1</td>\n",
       "      <td>im feel comfortable derby feel though start st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>i feel all weird when i have to meet w people ...</td>\n",
       "      <td>4</td>\n",
       "      <td>feel weird meet w people text like dont talk f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  \\\n",
       "0     im feeling rather rotten so im not very ambiti...      0   \n",
       "1             im updating my blog because i feel shitty      0   \n",
       "2     i never make her separate from me because i do...      0   \n",
       "3     i left with my bouquet of red and yellow tulip...      1   \n",
       "4       i was feeling a little vain when i did this one      0   \n",
       "...                                                 ...    ...   \n",
       "1995  i just keep feeling like someone is being unki...      3   \n",
       "1996  im feeling a little cranky negative after this...      3   \n",
       "1997  i feel that i am useful to my people and that ...      1   \n",
       "1998  im feeling more comfortable with derby i feel ...      1   \n",
       "1999  i feel all weird when i have to meet w people ...      4   \n",
       "\n",
       "                                      preprocessed_text  \n",
       "0              im feel rather rotten im ambitious right  \n",
       "1                            im update blog feel shitty  \n",
       "2       never make separate ever want feel like ashamed  \n",
       "3     left bouquet red yellow tulip arm feel slightl...  \n",
       "4                                  feel little vain one  \n",
       "...                                                 ...  \n",
       "1995  keep feel like someone unkind wrong think get ...  \n",
       "1996  im feel little cranky negative doctor appointment  \n",
       "1997     feel useful people give great feel achievement  \n",
       "1998  im feel comfortable derby feel though start st...  \n",
       "1999  feel weird meet w people text like dont talk f...  \n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocessor = TextPreprocessor(method='lemmatization', tokenizer='word', language='english')\n",
    "df_train['preprocessed_text'] = preprocessor.preprocess_texts(df_train['text'])\n",
    "df_train['preprocessed_text'] = df_train['preprocessed_text'].apply(lambda x: ' '.join(x))\n",
    "display(df_train)\n",
    "df_test['preprocessed_text'] = preprocessor.preprocess_texts(df_test['text'])\n",
    "df_test['preprocessed_text'] = df_test['preprocessed_text'].apply(lambda x: ' '.join(x))\n",
    "display(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f7c04dc-2f34-4693-b18a-22bf3bbcbfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Векторизация текстов с использованием TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=1000, lowercase=False, stop_words=None, analyzer='word')\n",
    "X_train = vectorizer.fit_transform(df_train['preprocessed_text'])\n",
    "X_test = vectorizer.transform(df_test['preprocessed_text'])\n",
    "\n",
    "\n",
    "vectorizer_original_texts = TfidfVectorizer(max_features=1000, lowercase=False, stop_words=None, analyzer='word')\n",
    "X_train_original_texts = vectorizer.fit_transform(df_train['text'])\n",
    "X_test_original_texts = vectorizer.transform(df_test['text'])\n",
    "\n",
    "y_train, y_test = df_train['label'], df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "306bafbb-e967-4ac5-8771-bb1aed085a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 (Logistic Regression on Preprocessed Texts): 0.6767943456685482\n",
      "F1 (Logistic Regression on Original Texts): 0.6267488913124267\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели линейной регрессии на предобработанных текстах\n",
    "LR_model_1 = LogisticRegression(max_iter=1000)\n",
    "LR_model_1.fit(X_train, y_train)\n",
    "predictions = LR_model_1.predict(X_test)\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    "print(f'F1 (Logistic Regression on Preprocessed Texts): {f1}')\n",
    "\n",
    "# Обучение модели линейной регрессии на непредобработанных текстах\n",
    "LR_model_2 = LogisticRegression(max_iter=1000)\n",
    "LR_model_2.fit(X_train_original_texts, y_train)\n",
    "predictions_processed = LR_model_2.predict(X_test_original_texts)\n",
    "f1_processed = f1_score(y_test, predictions_processed, average='macro')\n",
    "print(f'F1 (Logistic Regression on Original Texts): {f1_processed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "331aa707-05f5-4d09-a5f0-7c3257979095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 (Random Forest on Preprocessed Texts): 0.595787765277807\n",
      "F1 (Random Forest on Original Texts): 0.622330943974163\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Обучение модели случайного леса на предобработанных текстах\n",
    "RF_model_1 = RandomForestClassifier(n_estimators=100, max_depth=50, random_state=42)\n",
    "RF_model_1.fit(X_train, y_train)\n",
    "predictions_rf = RF_model_1.predict(X_test)\n",
    "f1_rf = f1_score(y_test, predictions_rf, average='macro')\n",
    "print(f'F1 (Random Forest on Preprocessed Texts): {f1_rf}')\n",
    "\n",
    "# Обучение модели случайного леса на непредобработанных текстах\n",
    "RF_model_2 = RandomForestClassifier(n_estimators=100, max_depth=50, random_state=42)\n",
    "RF_model_2.fit(X_train_original_texts, y_train)\n",
    "predictions_rf_processed = RF_model_2.predict(X_test_original_texts)\n",
    "f1_rf_processed = f1_score(y_test, predictions_rf_processed, average='macro')\n",
    "print(f'F1 (Random Forest on Original Texts): {f1_rf_processed}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8d4d2a5-e5ef-4395-8ee7-97d056197429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 (MLP on Preprocessed Texts): 0.7038576786240373\n",
      "F1 (MLP on Original Texts): 0.6835235961994314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Обучение MLP на предобработанных текстах\n",
    "MLP_model_1 = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "MLP_model_1.fit(X_train, y_train)\n",
    "predictions_mlp = MLP_model_1.predict(X_test)\n",
    "f1_mlp = f1_score(y_test, predictions_mlp, average='macro')\n",
    "print(f'F1 (MLP on Preprocessed Texts): {f1_mlp}')\n",
    "\n",
    "# Обучение MLP на непредобработанных текстах\n",
    "MLP_model_2 = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "MLP_model_2.fit(X_train_original_texts, y_train)\n",
    "predictions_mlp_processed = MLP_model_2.predict(X_test_original_texts)\n",
    "f1_mlp_processed = f1_score(y_test, predictions_mlp_processed, average='macro')\n",
    "print(f'F1 (MLP on Original Texts): {f1_mlp_processed}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774d4790-f64b-4aa3-8d82-db8c7725dd4f",
   "metadata": {},
   "source": [
    "# Рекомендации по предобработке текста (выводы)\n",
    "\n",
    "### 1. Ограниченная предобработка текста\n",
    "\n",
    "- Не всегда полная предобработка текста способствует улучшению показателей модели.\n",
    "- В некоторых случаях достаточно ограничиться удалением HTML-тегов, ссылок и приведением текста к нижнему регистру, чтобы добиться хороших результатов.\n",
    "\n",
    "### 2. Влияние модели на результаты предобработки\n",
    "\n",
    "- Разные модели могут по-разному реагировать на предобработанные и непредобработанные тексты.\n",
    "- Важно тестировать несколько моделей, чтобы определить, какая из них лучше справляется с данными в зависимости от степени предобработки.\n",
    "\n",
    "### 3. Важность полной предобработки при малом объеме данных\n",
    "\n",
    "- При небольшом объеме данных предобработка становится критически важной, так как множество различных способов написания одних и тех же слов без лемматизации могут быть интерпретированы как разные слова.*\n",
    "- Лемматизация помогает модели правильно сопоставлять слова, увеличивая её способность обобщать и правильно классифицировать тексты.\n",
    "\n",
    "### 4. Важность полной предобработки при большом объеме данных и ограниченных ресурсах\n",
    "\n",
    "- При больших объемах данных и ограниченных вычислительных ресурсах, предобработка может помочь уменьшить размерность данных и ускорить обучение модели.\n",
    "- Полная предобработка уменьшает количество уникальных слов, что снижает размерность TF-IDF векторов и сокращает время обучения модели.\n",
    "\n",
    "## Заключение\n",
    "\n",
    "Подход к предобработке текста должен быть адаптирован под конкретные условия использования, включая тип модели, размер и сложность данных, а также доступные вычислительные ресурсы. Регулярное тестирование и оценка различных подходов к предобработке помогут оптимизировать процесс и улучшить результаты классификации.\n",
    "\n",
    "\n",
    "****К примеру, у нас 200 строк на 1 класс. У этого класса есть слово триггер - \"get\", у которого формы: get, gotten(have got), gets, got, getting (т.е. когда оно есть, то мы с большой вероятностью можем определить объект к этому классу); Для ML-модели все эти формы будут разными словами (это будут разные токены), а если еще учесть что это слово будет встречается не во всех строках, то определить его без лемматизации будет достаточно сложно.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afd9276-6c53-4de4-acf6-feeac737e8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interns_kernel",
   "language": "python",
   "name": "interns_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
