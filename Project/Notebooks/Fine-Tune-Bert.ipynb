{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8245de6-96b6-46af-9072-84b7e8756d03",
   "metadata": {},
   "source": [
    "<center><h1 style=\"font-size: 40px\"> Дообученная модель ruBert для задачи экстрактной суммаризации текстов.</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fb92d7-50a2-4c14-9424-9d68f5c85f85",
   "metadata": {},
   "source": [
    "# Содержание\n",
    "### 1. [Дообучение ruBert](#chapter1)\n",
    "#### 1.1. [Загрузка модели](#chapter1.1)\n",
    "#### 1.2. [Загрузка и предобработка датасета](#chapter1.2)\n",
    "#### 1.3. [Дообучение модели ruBert](#chapter1.3)\n",
    "#### 1.4. [Тестирование дообученной модели](#chapter1.4)\n",
    "\n",
    "### 2. [Суммаризация текста](#chapter2)\n",
    "#### 2.1. [Использование библиотеки summarizer](#chapter2.1)\n",
    "#### 2.2. [Подсчёт всех метрик](#chapter2.2)\n",
    "\n",
    "### 3. [Вывод](#chapter3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddd99e41-3dd6-4537-92bd-ed12e496077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c01d458-1883-4774-8e72-e3740363d1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a04593f-df18-4a05-882a-900cdecafa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertForSequenceClassification, BertTokenizer, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04defed0-7a13-43ca-82a0-e0fe6f2133cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763f8b25-40e5-4a11-b926-44738d1950c1",
   "metadata": {},
   "source": [
    "<center id=\"chapter1\"><h1 style=\"font-size: 24px\"> 1. Дообучение ruBert </h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c396624-77ba-441e-9c80-2a3057ce0680",
   "metadata": {},
   "source": [
    "## 1.1. Загрузка модели <a id=\"chapter1.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "901c3463-c380-4c0c-b02b-4544e8e5efb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'DeepPavlov/rubert-base-cased'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "custom_model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2, output_hidden_states=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea6a069-ba85-428f-9e67-8689068b50e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4870bf7a-f760-4400-919a-1542b792d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зафиксируем веса базовой модели, чтобы при обучении их не трогать и обучать только последний слой (классификатор)\n",
    "for param in custom_model.base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd571c2e-3bb5-418d-aa38-5e5660953aa6",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5e36a4-8d75-4205-b1db-a23ac873d024",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d9574a-dd17-40a5-9feb-40ad4afc8976",
   "metadata": {},
   "source": [
    "## 1.2. Получение и предобработка данных <a id=\"chapter1.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bf2991-039f-403e-9f24-0db091b5fe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исходный датасет для задачи экстрактной суммаризации\n",
    "dataset = pd.read_pickle(\"../Data/ru_train.pkl\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bb636e-363b-4184-8cb2-6f520422a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_classification_df(dataset):\n",
    "    \"\"\"\n",
    "    Преобразует исходный датасет в формат, подходящий для решения задачи бинарной классификации.\n",
    "    \"\"\"\n",
    "    train_df = pd.DataFrame()\n",
    "    \n",
    "    sentences = []\n",
    "    labels = []\n",
    "\n",
    "    for i in dataset.index:\n",
    "        sentences += list(dataset.loc[i][\"sentences\"])\n",
    "        labels += list(dataset.loc[i][\"labels\"])\n",
    "\n",
    "    train_df[\"sentence\"] = sentences\n",
    "    train_df[\"label\"] = labels\n",
    "\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66689674-0e8b-474b-9945-8bf7300f8ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим датасет бинарной классификации на части текстов для начала\n",
    "df = make_classification_df(dataset.loc[0:99])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d361dd-1e92-4dff-8f94-a6331c720673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пусть обучающая часть содержит 80% предложений, а в валидационной и тестовой оставим по 10%\n",
    "df_train = df.loc[0:int(len(df)*0.8)]\n",
    "df_val = df.loc[int(len(df)*0.8)+1:int(len(df)*0.9)]\n",
    "df_test = df.loc[int(len(df)*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c126112-3b75-419e-85d0-4189461a273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train)\n",
    "display(df_val)\n",
    "display(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22378ba-2ca8-4de7-9b26-ffee60e9051a",
   "metadata": {},
   "source": [
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcdd482-5def-4f61-b118-4847707d2bf5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1981dc6d-58c9-4adb-8a26-ad164d218b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    \"\"\"Класс для преобразования датасета к нужному формату\"\"\"\n",
    "    def __init__(self, dataframe, tokenizer, max_len=64):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sentences = dataframe['sentence'].tolist()\n",
    "        self.labels = dataframe['label'].tolist()\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.sentences[idx]\n",
    "        label = self.labels[idx]\n",
    "        # токенизируем\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text=text, # наши данные\n",
    "            text_pair=None, # это для задачи вопросно-ответной системы, т.е. не для нас\n",
    "            add_special_tokens=True, # добавление спец-токенов, отвечающих за \"начало предложения\" [CLS] и \"конец предложения\" [SEP]\n",
    "            max_length=self.max_len, # максимальная длина последовательности\n",
    "            padding='max_length', # если в предложении меньше 64 токенов, то остальные заменяем на пустые\n",
    "            truncation=True, # если в предложениее 64+ токенов, то мы просто обрезаем их\n",
    "            return_token_type_ids=False, # это для задачи вопросно-ответной системы, т.е. не для нас\n",
    "            return_attention_mask=True, # это говорит нашей модели, какие токены важны, а какие просто как padding или [CLS] и т.д.\n",
    "            return_tensors='pt' # формат выдачи токенизатора, в нашем случае - torch тензор\n",
    "        )\n",
    "\n",
    "        # то что мы запихнем в модель\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(), # это наши цифровые токены (т.е. для токена 'привет' будет какое-нибудь '105')\n",
    "            'attention_mask': inputs['attention_mask'].flatten(), # это наши маски\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb135de-d37f-4b50-8acb-c1bededc72b4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fc0c7d-5e6d-42fd-b84e-c26b0bce0785",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(df_train, tokenizer)\n",
    "val_dataset = TextDataset(df_val, tokenizer)\n",
    "test_dataset = TextDataset(df_test, tokenizer)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce98243b-d406-4a41-b8a8-5c356aead410",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e20741-2e54-4627-9460-4202001fcc15",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef66228-c88a-4856-92bb-0b39180e681b",
   "metadata": {},
   "source": [
    "## 1.3. Дообучение ruBert <a id=\"chapter1.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8030c3-49f8-4849-b57c-b8218d29a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1744fdeb-e787-4c85-86b1-8ddad14d6fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_val(model, train_data_loader, val_data_loader, loss_fn, optimizer, device, num_epochs):\n",
    "    for t in tqdm(range(num_epochs)):\n",
    "        train_epoch_loss = []\n",
    "        eval_epoch_loss = []\n",
    "\n",
    "        # Будем сохранять правильные метки и предсказания для расчёта метрики f1\n",
    "        train_labels = []\n",
    "        train_predictions = []\n",
    "\n",
    "        eval_labels = []\n",
    "        eval_predictions = []\n",
    "        \n",
    "        print(\"Эпоха номер: \", t)\n",
    "\n",
    "        # Обучение модели на текущей эпохе\n",
    "        model.train()\n",
    "        for train_data in tqdm(train_data_loader):\n",
    "            input_ids = train_data['input_ids'].to(device) # токены\n",
    "            attention_mask = train_data['attention_mask'].to(device) # маски\n",
    "            labels = train_data['labels'].to(device) # класс\n",
    "\n",
    "            train_labels += list(labels)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask) # результат модели\n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "\n",
    "            train_predictions += list(preds)\n",
    "            \n",
    "            loss = loss_fn(outputs.logits, labels) # считаем потерю\n",
    "            train_epoch_loss.append(loss.item())\n",
    "\n",
    "\n",
    "            # Выполним подсчёт новых градиентов\n",
    "            loss.backward()\n",
    "            # Выполним шаг градиентного спуска\n",
    "            optimizer.step()\n",
    "            # Обнулим сохраненные у оптимизатора значения градиентов\n",
    "            # перед следующим шагом обучения\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Оценка модели на валидационных данных после обучения на текущей эпохе\n",
    "        model.eval()\n",
    "        for val_data in tqdm(val_data_loader):\n",
    "            input_ids = val_data['input_ids'].to(device) # токены\n",
    "            attention_mask = val_data['attention_mask'].to(device) # маски\n",
    "            labels = val_data['labels'].to(device) # класс\n",
    "\n",
    "            eval_labels += list(labels)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask) # результат модели\n",
    "                _, preds = torch.max(outputs.logits, dim=1)\n",
    "\n",
    "                eval_predictions += list(preds)\n",
    "            \n",
    "                loss = loss_fn(outputs.logits, labels) # считаем потерю\n",
    "                eval_epoch_loss.append(loss.item())\n",
    "\n",
    "        # Выведем результаты прошедшей эпохи обучения\n",
    "        print(\"Train loss: \", np.mean(train_epoch_loss))\n",
    "        print(\"Eval loss: \", np.mean(eval_epoch_loss))\n",
    "        print(\"Train F1-score: \", f1_score(train_labels, train_predictions))\n",
    "        print(\"Eval F1-score: \", f1_score(eval_labels, eval_predictions))\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a89a7a-0fc0-41d2-8e7f-dec212d6ed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "from transformers import AdamW\n",
    "optimizer = AdamW(custom_model.parameters(), lr=1e-5)\n",
    "\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb03543d-5574-4c1e-b900-85322c0ec59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = train_val(custom_model, train_data_loader, val_data_loader, loss_fn, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57af328b-27ba-48c2-bea6-1b56ff586f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(custom_model.state_dict(), \"custom_rubert_clf.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0096770d-ea17-4b5b-b6b7-d1f6963b0729",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "              \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb53ecc3-241f-469f-a26e-c17b725717ba",
   "metadata": {},
   "source": [
    "## 1.4. Тестирование дообученной модели <a id=\"chapter1.4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5389c3-a71c-4eb0-ba56-b46daf5f6a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2, output_hidden_states=True).to(device)\n",
    "model.load_state_dict(torch.load(\"custom_rubert_clf.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cb59cf-cb31-4b0c-a8d1-e80b1282826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict(model, test_data_loader):\n",
    "    test_labels = []\n",
    "    test_predictions = [] \n",
    "    \n",
    "    for test_data in tqdm(test_data_loader):\n",
    "        input_ids = test_data['input_ids'].to(device) # токены\n",
    "        attention_mask = test_data['attention_mask'].to(device) # маски\n",
    "        labels = test_data['labels'].to(device) # класс\n",
    "\n",
    "        test_labels += labels.tolist()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask) # результат модели\n",
    "        _, preds = torch.max(outputs.logits, dim=1)\n",
    "\n",
    "        test_predictions += preds.tolist()\n",
    "\n",
    "    print(f1_score(test_labels, test_predictions))\n",
    "    \n",
    "    return test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87d52ee-8cf9-452d-8536-bbbdd5710f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    df_test[\"predictions\"] = test_predict(custom_model, test_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea01665-fccf-44c1-8079-285a3885256d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee208afe-f9dc-4eb2-977b-a64e5e735306",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1221eb4-cd13-4300-a43f-ea29f8c61248",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52257c5b-8af7-4a9f-adf4-977d153bf467",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75c4632-6a18-4462-8364-34d6fb10dd16",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6680c1c-9bb8-4cc6-aaa8-10abebcf8748",
   "metadata": {},
   "source": [
    "<center id=\"chapter2\"><h1 style=\"font-size: 24px\"> 2. Суммаризация текста </h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e77ac8-6338-4622-9a19-29396fb8e21f",
   "metadata": {},
   "source": [
    "Наш датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d705b7a9-96d4-47ad-96cc-88c784427aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(CNN) Палестинская администрация официально с...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(CNN) Не говоря уже о кошках, у которых девят...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(CNN) Если вы в последнее время следили за но...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(CNN) Пятеро американцев, за которыми в течен...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(CNN) Студент Дьюка признался, что повесил пе...</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[(CNN) Он первоклассный баскетбольный новобран...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[(CNN) Правительства во всем мире используют у...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[(CNN) Эндрю Гетти, один из наследников миллиа...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[(CNN) Филиппинцев предупреждают, чтобы они бы...</td>\n",
       "      <td>[0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[(CNN) Впервые за восемь лет легенда телевиден...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[Лондон (CNN) 19-летнему мужчине в среду было ...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentences  \\\n",
       "0   [(CNN) Палестинская администрация официально с...   \n",
       "1   [(CNN) Не говоря уже о кошках, у которых девят...   \n",
       "2   [(CNN) Если вы в последнее время следили за но...   \n",
       "3   [(CNN) Пятеро американцев, за которыми в течен...   \n",
       "4   [(CNN) Студент Дьюка признался, что повесил пе...   \n",
       "5   [(CNN) Он первоклассный баскетбольный новобран...   \n",
       "6   [(CNN) Правительства во всем мире используют у...   \n",
       "7   [(CNN) Эндрю Гетти, один из наследников миллиа...   \n",
       "8   [(CNN) Филиппинцев предупреждают, чтобы они бы...   \n",
       "9   [(CNN) Впервые за восемь лет легенда телевиден...   \n",
       "10  [Лондон (CNN) 19-летнему мужчине в среду было ...   \n",
       "\n",
       "                                               labels  \n",
       "0   [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1   [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2   [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3                   [0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]  \n",
       "4   [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "5   [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "6   [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "7   [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "8    [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "9                                  [0, 0, 1, 1, 0, 0]  \n",
       "10                                 [1, 1, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extsum_dataset = pd.read_pickle(\"../Data/ru_test_5k.pkl\")\n",
    "extsum_dataset = pd.DataFrame(extsum_dataset[['ru_src', 'labels']].values, columns=['sentences', 'labels'])\n",
    "# Взял небольшое количество для проверки кода\n",
    "extsum_dataset_sample = extsum_dataset.loc[0:10]\n",
    "extsum_dataset_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c629cf9a-9a4e-4048-98eb-e93147cd3047",
   "metadata": {},
   "source": [
    "Наша кастомная модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce609d6c-c3cf-47a0-8853-b252451d841a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2, output_hidden_states=True).to(device)\n",
    "custom_model.load_state_dict(torch.load(\"custom_rubert_clf.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5771c3c-7280-49ba-9b7d-ae601a3a44bd",
   "metadata": {},
   "source": [
    "## 2.1. Использование библиотеки summarizer <a id=\"chapter2.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2e770a5-5d7d-4df5-b62d-9df28377aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarizer import Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7b8e8cc-43a1-476c-a4c3-2452d27e3f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertsum_custom_model = Summarizer(custom_model=custom_model, custom_tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3bd6fd6-baf8-47a4-836e-8c677d8d1eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(CNN) Палестинская администрация официально стала 123-м членом Международного уголовного суда в среду, шаг, который дает суду юрисдикцию над предполагаемыми преступлениями на палестинских территориях. Официальное вступление было отмечено церемонией в Гааге (Нидерланды), где находится суд. Палестинцы подписали основополагающий Римский статут МУС в январе, когда они также признали его юрисдикцию в отношении предполагаемых преступлений, совершенных «на оккупированной палестинской территории, включая Восточный Иерусалим, с 13 июня 2014 года». Позже в том же месяце МУС начал предварительное расследование ситуации на палестинских территориях, открыв путь для возможного расследования военных преступлений против израильтян. Палестинцам, как членам суда, также могут быть предъявлены встречные обвинения. Израиль и США, ни одна из которых не является членом МУС, выступили против попыток палестинцев присоединиться к этому органу. Но министр иностранных дел Палестины Риад аль-Малики, выступая на церемонии в среду, заявил, что это шаг к большей справедливости. «Поскольку Палестина сегодня официально становится государством-участником Римского статута, мир также стал на шаг ближе к окончанию долгой эпохи безнаказанности и несправедливости», - сказал он, согласно пресс-релизу МУС. «Действительно, сегодняшний день приближает нас к нашим общим целям справедливости и мира». Судья Кунико Озаки, вице-президент МУС, заявила, что присоединение к договору было лишь первым шагом для палестинцев. «Поскольку сегодня Римский статут вступает в силу для Государства Палестина, Палестина приобретает все права и обязанности, вытекающие из статуса государства-участника Статута. Это существенные обязательства, к которым нельзя относиться легкомысленно\", - сказала она. Правозащитная группа Human Rights Watch приветствовала такое развитие событий. «Правительства, стремящиеся наказать Палестину за присоединение к МУС, должны немедленно прекратить свое давление, а страны, которые поддерживают всеобщее признание договора о суде, должны высказаться и приветствовать ее членство», - сказал Балкис Джарра, советник по международному правосудию группы. «Что вызывает возражения, так это попытки подорвать международное правосудие, а не решение Палестины присоединиться к договору, участниками которого являются более 100 стран мира». В январе, когда было открыто предварительное расследование МУС, премьер-министр Израиля Биньямин Нетаньяху назвал это возмутительным, заявив, что суд выходит за свои рамки. Соединенные Штаты также заявили, что «категорически» не согласны с решением суда. «Как мы неоднократно заявляли, мы не считаем, что Палестина является государством, и поэтому не считаем, что она имеет право присоединиться к МУС», — говорится в заявлении Госдепартамента. Он призвал воюющие стороны урегулировать свои разногласия путем прямых переговоров. «Мы продолжим выступать против действий против Израиля в МУС как контрпродуктивных для дела мира», - говорится в заявлении. Но МУС не согласен с определением государства для своих целей и называет территории «Палестиной». Хотя предварительное следствие не является формальным расследованием, оно позволяет суду рассмотреть доказательства и определить, следует ли проводить расследование в отношении подозреваемых с обеих сторон. Прокурор Фату Бенсуда заявила, что ее офис «проведет анализ полностью независимо и беспристрастно». Война между Израилем и боевиками ХАМАС в Газе прошлым летом унесла жизни более 2000 человек. Расследование будет включать предполагаемые военные преступления, совершенные с июня. Международный уголовный суд был создан в 2002 году для преследования геноцида, преступлений против человечности и военных преступлений. Васко Котовио из CNN, Карим Хаддер и Фейт Карими внесли свой вклад в подготовку этого репортажа.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" \".join(extsum_dataset_sample.loc[0][\"sentences\"])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1347fa50-1bc3-4e54-b7e3-c87a0d646342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(CNN) Палестинская администрация официально стала 123-м членом Международного уголовного суда в среду, шаг, который дает суду юрисдикцию над предполагаемыми преступлениями на палестинских территориях. Правительства, стремящиеся наказать Палестину за присоединение к МУС, должны немедленно прекратить свое давление, а страны, которые поддерживают всеобщее признание договора о суде, должны высказаться и приветствовать ее членство», - сказал Балкис Джарра, советник по международному правосудию группы. « Международный уголовный суд был создан в 2002 году для преследования геноцида, преступлений против человечности и военных преступлений.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertsum_custom_model(text, num_sentences=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312360f6-0145-4002-bb33-28abe9222e77",
   "metadata": {},
   "source": [
    "## 2.2. Подсчёт всех метрик <a id=\"chapter2.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e66e27c-2fb6-4653-9988-897424eefc2f",
   "metadata": {},
   "source": [
    "Наши предыдущие результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0960e15c-8ea2-4f94-a59e-fb7f06b1e7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>bleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>bert_precision</th>\n",
       "      <th>bert_recall</th>\n",
       "      <th>bert_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TextRank</th>\n",
       "      <td>0.211472</td>\n",
       "      <td>0.106501</td>\n",
       "      <td>0.206855</td>\n",
       "      <td>0.206569</td>\n",
       "      <td>0.178233</td>\n",
       "      <td>0.312205</td>\n",
       "      <td>0.732481</td>\n",
       "      <td>0.754939</td>\n",
       "      <td>0.743080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LexRank</th>\n",
       "      <td>0.235729</td>\n",
       "      <td>0.118226</td>\n",
       "      <td>0.230788</td>\n",
       "      <td>0.230648</td>\n",
       "      <td>0.261628</td>\n",
       "      <td>0.322667</td>\n",
       "      <td>0.736673</td>\n",
       "      <td>0.737441</td>\n",
       "      <td>0.736529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSA</th>\n",
       "      <td>0.173570</td>\n",
       "      <td>0.078269</td>\n",
       "      <td>0.170758</td>\n",
       "      <td>0.170495</td>\n",
       "      <td>0.175943</td>\n",
       "      <td>0.269465</td>\n",
       "      <td>0.704227</td>\n",
       "      <td>0.721596</td>\n",
       "      <td>0.712457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KL</th>\n",
       "      <td>0.203493</td>\n",
       "      <td>0.100092</td>\n",
       "      <td>0.200029</td>\n",
       "      <td>0.200301</td>\n",
       "      <td>0.191725</td>\n",
       "      <td>0.295647</td>\n",
       "      <td>0.712154</td>\n",
       "      <td>0.728635</td>\n",
       "      <td>0.719865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luhn</th>\n",
       "      <td>0.228917</td>\n",
       "      <td>0.113189</td>\n",
       "      <td>0.224979</td>\n",
       "      <td>0.224915</td>\n",
       "      <td>0.230286</td>\n",
       "      <td>0.346023</td>\n",
       "      <td>0.727853</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.734508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BertSum</th>\n",
       "      <td>0.245710</td>\n",
       "      <td>0.116171</td>\n",
       "      <td>0.241740</td>\n",
       "      <td>0.242022</td>\n",
       "      <td>0.242611</td>\n",
       "      <td>0.374681</td>\n",
       "      <td>0.732481</td>\n",
       "      <td>0.754939</td>\n",
       "      <td>0.743080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum      bleu    meteor  \\\n",
       "TextRank  0.211472  0.106501  0.206855   0.206569  0.178233  0.312205   \n",
       "LexRank   0.235729  0.118226  0.230788   0.230648  0.261628  0.322667   \n",
       "LSA       0.173570  0.078269  0.170758   0.170495  0.175943  0.269465   \n",
       "KL        0.203493  0.100092  0.200029   0.200301  0.191725  0.295647   \n",
       "Luhn      0.228917  0.113189  0.224979   0.224915  0.230286  0.346023   \n",
       "BertSum   0.245710  0.116171  0.241740   0.242022  0.242611  0.374681   \n",
       "\n",
       "          bert_precision  bert_recall   bert_f1  \n",
       "TextRank        0.732481     0.754939  0.743080  \n",
       "LexRank         0.736673     0.737441  0.736529  \n",
       "LSA             0.704227     0.721596  0.712457  \n",
       "KL              0.712154     0.728635  0.719865  \n",
       "Luhn            0.727853     0.742424  0.734508  \n",
       "BertSum         0.732481     0.754939  0.743080  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results = pd.read_csv(\"final_results.csv\", index_col=0)\n",
    "final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b01478-24c6-4fb9-999f-e038c72a8761",
   "metadata": {},
   "source": [
    "Наши метрики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0786f3c7-4f49-47fd-a7d5-d938cc0d58bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75de7e66-449d-4395-aac8-7357e0518c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Максат\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Максат\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Максат\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu  = evaluate.load(\"bleu\")\n",
    "meteor = evaluate.load('meteor')\n",
    "\n",
    "bertscore  = evaluate.load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "198f4b7c-d28d-478c-8ca4-a99d5d6165ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(generated_summaries, reference_summaries):\n",
    "    \n",
    "    metrics_dict = rouge.compute(predictions=generated_summaries, references=reference_summaries)\n",
    "    metrics_dict[\"bleu\"] = bleu.compute(predictions=generated_summaries, references=reference_summaries)[\"bleu\"]\n",
    "    metrics_dict[\"meteor\"] = meteor.compute(predictions=generated_summaries, references=reference_summaries)[\"meteor\"]\n",
    "\n",
    "    bertscore_results = bertscore.compute(predictions=generated_summaries, references=reference_summaries, lang='ru')\n",
    "    \n",
    "    bert_dict = {'bert_precision': np.mean(bertscore_results['precision']), \n",
    "                 'bert_recall': np.mean(bertscore_results['recall']),\n",
    "                'bert_f1': np.mean(bertscore_results['f1'])}\n",
    "    \n",
    "    return metrics_dict | bert_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46c1968f-e17c-4d22-8187-825214e2db10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference_summary(sentences, labels):\n",
    "    \"\"\" \n",
    "    Получение образцовой экстрактивной суммаризации по массиву предложений и по маске входящих в суммаризацию предложений\n",
    "    Параметры:\n",
    "        sentences - массив строк(предложений)\n",
    "        labels - маска предложений, 1 - предложение входит в суммаризацию, 0 - не входит\n",
    "    Возвращает:\n",
    "        строку\n",
    "    \"\"\"\n",
    "    labels = [x==1 for x in labels]\n",
    "    \n",
    "    reference_summary = np.array(sentences)[labels]\n",
    "\n",
    "    return ' '.join(reference_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1d799d7-175f-416f-a6c3-5e35e7d65e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>References</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Позже в том же месяце МУС начал предварительно...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ее взяла к себе жительница Мозес-Лейк, штат Ва...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Он, конечно, министр иностранных дел Ирана. В ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>В марте они заразились Эболой в Сьерра-Леоне, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(CNN) Студент Дьюка признался, что повесил пет...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Она первокурсница средней школы с синдромом Да...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(CNN) Правительства во всем мире используют уг...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Родители Гетти, Энн и Гордон Гетти, опубликова...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Всего несколько дней назад Майсак получил стат...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>в выпуске «The Price Is Right» от 1 апреля я в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Лондон (CNN) 19-летнему мужчине в среду было п...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           References\n",
       "0   Позже в том же месяце МУС начал предварительно...\n",
       "1   Ее взяла к себе жительница Мозес-Лейк, штат Ва...\n",
       "2   Он, конечно, министр иностранных дел Ирана. В ...\n",
       "3   В марте они заразились Эболой в Сьерра-Леоне, ...\n",
       "4   (CNN) Студент Дьюка признался, что повесил пет...\n",
       "5   Она первокурсница средней школы с синдромом Да...\n",
       "6   (CNN) Правительства во всем мире используют уг...\n",
       "7   Родители Гетти, Энн и Гордон Гетти, опубликова...\n",
       "8   Всего несколько дней назад Майсак получил стат...\n",
       "9   в выпуске «The Price Is Right» от 1 апреля я в...\n",
       "10  Лондон (CNN) 19-летнему мужчине в среду было п..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# В этом датафрейме будет два столбца:\n",
    "# 1. References - эталонные суцммаризации\n",
    "# 2. CustomBertSum - сгенерированные суммаризации \n",
    "df_results = pd.DataFrame()\n",
    "\n",
    "# Заполняем столбец References\n",
    "df_results[\"References\"] = extsum_dataset_sample[['sentences', 'labels']].apply(lambda cols: get_reference_summary(cols['sentences'], cols['labels']) , axis=1)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11f58096-9062-4b9b-859d-94493a03c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Суммаризируем все тексты\n",
    "df_results['CustomBertSum'] = extsum_dataset_sample[['sentences', 'labels']].apply(lambda cols: bertsum_custom_model(' '.join(cols['sentences']), num_sentences=sum(cols['labels'])),\n",
    "                                                          axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19665696-d538-4a0d-ad1b-6b9ca0076098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cохраним на всякий полученные суммаризации\n",
    "df_results.to_pickle(\"custom_bert_summarizations.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0cf6b6c-c1c0-4852-a3c0-24a836d2f931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.2121212121212121,\n",
       " 'rouge2': 0.14285714285714288,\n",
       " 'rougeL': 0.2121212121212121,\n",
       " 'rougeLsum': 0.2121212121212121,\n",
       " 'bleu': 0.24579650073762876,\n",
       " 'meteor': 0.37461433231653807,\n",
       " 'bert_precision': 0.7227218801325018,\n",
       " 'bert_recall': 0.7554647109725259,\n",
       " 'bert_f1': 0.7385479536923495}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посчитаем все метрики\n",
    "metrics_dict = get_metrics(df_results['CustomBertSum'].values, df_results[\"References\"].values)\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08c203ff-fa04-4468-9556-27bbd698ca06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>bleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>bert_precision</th>\n",
       "      <th>bert_recall</th>\n",
       "      <th>bert_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TextRank</th>\n",
       "      <td>0.211472</td>\n",
       "      <td>0.106501</td>\n",
       "      <td>0.206855</td>\n",
       "      <td>0.206569</td>\n",
       "      <td>0.178233</td>\n",
       "      <td>0.312205</td>\n",
       "      <td>0.732481</td>\n",
       "      <td>0.754939</td>\n",
       "      <td>0.743080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LexRank</th>\n",
       "      <td>0.235729</td>\n",
       "      <td>0.118226</td>\n",
       "      <td>0.230788</td>\n",
       "      <td>0.230648</td>\n",
       "      <td>0.261628</td>\n",
       "      <td>0.322667</td>\n",
       "      <td>0.736673</td>\n",
       "      <td>0.737441</td>\n",
       "      <td>0.736529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSA</th>\n",
       "      <td>0.173570</td>\n",
       "      <td>0.078269</td>\n",
       "      <td>0.170758</td>\n",
       "      <td>0.170495</td>\n",
       "      <td>0.175943</td>\n",
       "      <td>0.269465</td>\n",
       "      <td>0.704227</td>\n",
       "      <td>0.721596</td>\n",
       "      <td>0.712457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KL</th>\n",
       "      <td>0.203493</td>\n",
       "      <td>0.100092</td>\n",
       "      <td>0.200029</td>\n",
       "      <td>0.200301</td>\n",
       "      <td>0.191725</td>\n",
       "      <td>0.295647</td>\n",
       "      <td>0.712154</td>\n",
       "      <td>0.728635</td>\n",
       "      <td>0.719865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luhn</th>\n",
       "      <td>0.228917</td>\n",
       "      <td>0.113189</td>\n",
       "      <td>0.224979</td>\n",
       "      <td>0.224915</td>\n",
       "      <td>0.230286</td>\n",
       "      <td>0.346023</td>\n",
       "      <td>0.727853</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.734508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BertSum</th>\n",
       "      <td>0.245710</td>\n",
       "      <td>0.116171</td>\n",
       "      <td>0.241740</td>\n",
       "      <td>0.242022</td>\n",
       "      <td>0.242611</td>\n",
       "      <td>0.374681</td>\n",
       "      <td>0.732481</td>\n",
       "      <td>0.754939</td>\n",
       "      <td>0.743080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom Bert</th>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.245797</td>\n",
       "      <td>0.374614</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.755465</td>\n",
       "      <td>0.738548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               rouge1    rouge2    rougeL  rougeLsum      bleu    meteor  \\\n",
       "TextRank     0.211472  0.106501  0.206855   0.206569  0.178233  0.312205   \n",
       "LexRank      0.235729  0.118226  0.230788   0.230648  0.261628  0.322667   \n",
       "LSA          0.173570  0.078269  0.170758   0.170495  0.175943  0.269465   \n",
       "KL           0.203493  0.100092  0.200029   0.200301  0.191725  0.295647   \n",
       "Luhn         0.228917  0.113189  0.224979   0.224915  0.230286  0.346023   \n",
       "BertSum      0.245710  0.116171  0.241740   0.242022  0.242611  0.374681   \n",
       "Custom Bert  0.212121  0.142857  0.212121   0.212121  0.245797  0.374614   \n",
       "\n",
       "             bert_precision  bert_recall   bert_f1  \n",
       "TextRank           0.732481     0.754939  0.743080  \n",
       "LexRank            0.736673     0.737441  0.736529  \n",
       "LSA                0.704227     0.721596  0.712457  \n",
       "KL                 0.712154     0.728635  0.719865  \n",
       "Luhn               0.727853     0.742424  0.734508  \n",
       "BertSum            0.732481     0.754939  0.743080  \n",
       "Custom Bert        0.722722     0.755465  0.738548  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results.loc[\"Custom Bert\"] = metrics_dict\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac8a251-3432-4681-aac9-06a99a9c3c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "795268de-37e5-4b0a-82dd-1f6447bfce93",
   "metadata": {},
   "source": [
    "<center id=\"chapter3\"><h1 style=\"font-size: 24px\"> 3. Вывод </h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f438eaa-f281-42df-9abb-d67f0dc2fe27",
   "metadata": {},
   "source": [
    "Окончательный выбор лучшей модели! Ура!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1509691-4c7d-4ac8-a061-0231fde28ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
